{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare the optimized architecture to the actual architecture:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-15 11:47:11.989471: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-15 11:47:12.293751: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-02-15 11:47:12.293767: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-02-15 11:47:13.246932: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 11:47:13.247101: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-15 11:47:13.247110: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pymoo_implementation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpickle\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpymoo_implementation\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproblem\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproblem_mlp_optimization\u001b[39;00m \u001b[39mimport\u001b[39;00m create_MLP_from_parameter\n\u001b[1;32m     22\u001b[0m \u001b[39m# Setup jupyter\u001b[39;00m\n\u001b[1;32m     23\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mmatplotlib\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pymoo_implementation'"
     ]
    }
   ],
   "source": [
    "# Jupyter packagesb\n",
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Common packages, you know them from before \n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import math\n",
    "import copy\n",
    "from typing import *\n",
    "import json\n",
    "import string\n",
    "import os\n",
    "import pickle\n",
    "from pymoo_implementation.problem.problem_mlp_optimization import create_MLP_from_parameter\n",
    "\n",
    "# Setup jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = (os.getcwd().replace(\"scripts\", \"\"))\n",
    "PICKLE_NAME = f\"{PATH}pickled_data/res-ITIV-set1-20pop-6ly-2023-02-13.p\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set constants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_COUNT = 500000\n",
    "EVALUTAION_DATA_COUNT = TRAIN_DATA_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data constants\n",
    "data_path_1 = PATH + \"data/random1\"\n",
    "data_path_2 = PATH + \"data/random2\"\n",
    "data_path_3 = PATH + \"data/random3\"\n",
    "path_list = [data_path_1, data_path_2, data_path_3]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_path : string, data_count: int): \n",
    "    original_data = pd.read_csv(data_path, delimiter='\\t');\n",
    "    data = original_data.iloc[:\n",
    "    data_count\n",
    "    , 9:]\n",
    "    input = data.iloc[:, :-9]\n",
    "    target = data.iloc[:, -9:-7]\n",
    "\n",
    "    return input, target, len(original_data)\n",
    "\n",
    "input, target, lenght = get_data(data_path_3, TRAIN_DATA_COUNT)\n",
    "val_input, val_target, lenght = get_data(data_path_1, EVALUTAION_DATA_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_prep(model, input, target):    \n",
    "    y_pred = model.predict(input)\n",
    "\n",
    "    z_list = np.array([])\n",
    "    theta_list = np.array([])\n",
    "\n",
    "    true_z_list = np.array([])\n",
    "    true_theta_list = np.array([])\n",
    "\n",
    "    for element in y_pred:\n",
    "        z_list = np.append(z_list, element[0]) \n",
    "        theta_list = np.append(theta_list, element[1])\n",
    "\n",
    "    for element in target.values:\n",
    "        true_z_list = np.append(true_z_list, element[0]) \n",
    "        true_theta_list = np.append(true_theta_list, element[1])\n",
    "    \n",
    "    return z_list * 100, true_z_list * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(input_data, target_data, parameter):\n",
    "    # add early stopping callback to save time\n",
    "    es = EarlyStopping(monitor = 'val_accuracy', mode ='max', patience = 5)\n",
    "    # Train the model\n",
    "    cnn_model = create_MLP_from_parameter(parameter)\n",
    "    cnn_model.fit(input_data, target_data, epochs=500, validation_split = 0.2, batch_size=2, callbacks = [es], use_multiprocessing=True, verbose=0)\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pickle.load(open(PICKLE_NAME, \"rb\"))\n",
    "for history in res:\n",
    "        last_best = history[-1].opt.get(\"F\")  \n",
    "        pop = history[-1].opt.get(\"X\")    \n",
    "        print (last_best)\n",
    "        print (pop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the best solution (best acc) from the above:\n",
    "opt_parameter = pop[np.where(last_best == sorted(last_best,key=lambda x: x[0], reverse=False)[0])]\n",
    "opt_parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = load_model(input, target, opt_parameter)\n",
    "old_model = load_model(input, target, np.array([81]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_list_opt, true_z_list = data_prep(opt_model, val_input, val_target)\n",
    "z_list_old, true_z_list = data_prep(old_model, val_input, val_target)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot generations in scatter plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generation_plot(pickle_name, save_name):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(10, 10)\n",
    "\n",
    "    history_list = pickle.load( open(pickle_name, \"rb\"))\n",
    "\n",
    "    for entry in history_list[0]:\n",
    "        F = []\n",
    "        # for each algorithm object in the history\n",
    "        for result_history in history_list:\n",
    "\n",
    "            # for each algorithm object in the history\n",
    "            for entry in result_history:\n",
    "                if (len(F) == 0):\n",
    "                    F = (entry.pop.get(\"F\"))\n",
    "                else:\n",
    "                    F = np.append(F, entry.pop.get(\"F\"),axis=0)   \n",
    "\n",
    "    acc = [-i[0] for i in F]\n",
    "    sum =  [i[1] for i in F]\n",
    "    dWc =  [i[2] for i in F]\n",
    "\n",
    "    ax = plt.axes(projection = '3d')\n",
    "    plot = ax.scatter(sum, dWc, acc, c=acc, cmap='viridis')\n",
    "    ax.set_ylabel(\"Dead Weight Count\")\n",
    "    ax.set_xlabel(\"Sum parameters\")\n",
    "    ax.set_zlabel(\"Validation accuracy\")\n",
    "    ax.set_title(\"Accuracy compared to dead weight count and and parameter sum\\nfor all generations \")\n",
    "   \n",
    "    fig.tight_layout\n",
    "    fig.colorbar(plot, use_gridspec=True, )\n",
    "    fig.savefig(f\"{PATH}/plots/{save_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "get_generation_plot(PICKLE_NAME, f\"generation_plot_{opt_parameter}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performace comparision plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_z_deviation(opt_model,old_model, title, save_name, input, target):\n",
    "    opt_acc = opt_model.evaluate(input, target)[1]\n",
    "    old_acc = old_model.evaluate(input, target)[1]\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    hist_bins = np.linspace(-50, 50, 250)\n",
    "    fig.set_size_inches(12, 8)\n",
    "\n",
    "    #z_list_opt, true_z_list = data_prep(opt_model, input, target)\n",
    "    #z_list_old, true_z_list = data_prep(old_model, input, target)\n",
    "\n",
    "    delta_z_opt = (z_list_opt).astype(float) - (true_z_list).astype(float)\n",
    "    delta_z_old = (z_list_old).astype(float) - (true_z_list).astype(float)\n",
    "\n",
    "    print (true_z_list)\n",
    "    \n",
    "\n",
    "    ax.set_title(f'Deviation from true label')\n",
    "    ax.set_xlabel(\"Deviation from true label in cm (predicted_z - true_z)\")\n",
    "    ax.set_ylabel(\"Number of tracks\")\n",
    "    \n",
    "    ax.hist(delta_z_opt, hist_bins, density=False,  alpha=0.5, label=f'optimized architecture: {opt_parameter}, acc: {opt_acc:0.02f}')\n",
    "    ax.hist(delta_z_old, hist_bins, density=False,  alpha=0.5, label=f' old architecture: [81], acc: {old_acc:0.02f}')\n",
    "\n",
    "    ax.grid(True)\n",
    "    ax.legend(loc = 'upper left')\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"{PATH}/plots/{save_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "plot_z_deviation(opt_model, old_model, f'Comparing the architectures [81] and {opt_parameter} for {EVALUTAION_DATA_COUNT} tracks',  f\"z_deviation_{opt_parameter}\", val_input, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_prediciton_performance(opt_model,old_model, title, save_name, input, target):\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(22, 8)\n",
    "\n",
    "    #z_list_opt, true_z_list = data_prep(opt_model, input, target)\n",
    "    #z_list_old, true_z_list = data_prep(old_model, input, target)\n",
    "\n",
    "\n",
    "    ax[0].set_title(f'Performace old architecture')\n",
    "    ax[0].set_xlabel(\"True z\")\n",
    "    ax[0].set_ylabel(\"Predicted z\")\n",
    "\n",
    "    ax[0].hist2d(z_list_old, true_z_list, 100, density = False, range=[[-100, 100], [-100, 100]])\n",
    "\n",
    "    ax[1].set_title(f'Performace optimized architecture')\n",
    "    ax[1].set_xlabel(\"True z\")\n",
    "    ax[1].set_ylabel(\"Predicted z\")\n",
    "\n",
    "    plot = ax[1].hist2d(z_list_opt, true_z_list, 100, density = False, range=[[-100, 100], [-100, 100]])\n",
    "    fig.colorbar(plot[3], ax=ax)\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    fig.savefig(f\"{PATH}/plots/{save_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "plot_prediciton_performance(opt_model, old_model, f'Comparing the architectures [81] and {opt_parameter} for {EVALUTAION_DATA_COUNT} tracks',  f\"performace_{opt_parameter}\", val_input, val_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_z_distribution(opt_model, old_model, title, save_name, input, target):\n",
    "\n",
    "    hist_bins = np.linspace(-100, 100, 100)\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(16, 8)\n",
    "\n",
    "    #z_list_opt, true_z_list = data_prep(opt_model, input, target)\n",
    "    #z_list_old, true_z_list = data_prep(old_model, input, target)\n",
    "\n",
    "    ax[1].set_title(f'Optimized MLP z-distribution')\n",
    "    ax[0].set_xlabel(\"z in cm\")\n",
    "    ax[0].set_ylabel(\"Number of tracks\")\n",
    "\n",
    "    ax[0].set_title(f'Old MLP z-distribution')\n",
    "    ax[1].set_xlabel(\"z in cm\")\n",
    "    ax[1].set_ylabel(\"Number of tracks\")\n",
    "    \n",
    "    ax[1].hist(true_z_list, hist_bins, density=False, alpha = 1, label = 'target data')\n",
    "    ax[1].hist(z_list_opt, hist_bins, density=False, range=(-10, 10), alpha=0.5, label=f'predicted data \\n(from optimized MLP, {opt_parameter})')\n",
    "    \n",
    "    ax[0].hist(true_z_list, hist_bins, density=False, alpha = 1, label = 'target data')\n",
    "    ax[0].hist(z_list_old, hist_bins, density=False, range=(-10, 10), alpha=0.5, label='predicted data \\n(from old MLP, [81.])')\n",
    "    \n",
    "\n",
    "\n",
    "    ax[1].legend(loc = 'upper left')\n",
    "    ax[0].legend(loc = 'upper left')\n",
    "    \n",
    "    fig.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(f\"{PATH}/plots/{save_name}.png\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_z_distribution(opt_model, old_model, f'Comparision model z-distribution with reconstructed z-distribution withfor {EVALUTAION_DATA_COUNT} tracks',  f\"z_distribution{opt_parameter}\", val_input, val_target )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffa4fb3745a6512ef0ab2c8f4038ced844a3e74668069da71ee16b58ce275483"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
